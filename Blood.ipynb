{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/81/07/be624c7e0a63b080a76b7f6faf417eecdc5f6480f6a740a8bcf8991bce0b/tensorflow-1.12.0-cp36-cp36m-macosx_10_11_x86_64.whl (62.0MB)\n",
      "\u001b[K    100% |################################| 62.0MB 375kB/s ta 0:00:011    53% |#################               | 33.1MB 2.3MB/s eta 0:00:13    59% |##################              | 36.7MB 1.6MB/s eta 0:00:16    81% |#########################       | 50.4MB 1.2MB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (0.6.2)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (1.0.5)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c7/27/133f225035b9539f2dcfebcdf9a69ff0152f56e0120160ec5c972ea7deb9/protobuf-3.6.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |################################| 1.2MB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting tensorboard<1.13.0,>=1.12.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\n",
      "\u001b[K    100% |################################| 3.1MB 1.4MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (1.0.6)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (1.14.2)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (0.30.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorflow) (0.1.11)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (38.5.2)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (2.6.11)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Installing collected packages: protobuf, tensorboard, tensorflow\n",
      "  Found existing installation: protobuf 3.5.2\n",
      "    Uninstalling protobuf-3.5.2:\n",
      "      Successfully uninstalled protobuf-3.5.2\n",
      "  Found existing installation: tensorboard 1.6.0\n",
      "    Uninstalling tensorboard-1.6.0:\n",
      "      Successfully uninstalled tensorboard-1.6.0\n",
      "  Found existing installation: tensorflow 1.4.0\n",
      "    Uninstalling tensorflow-1.4.0:\n",
      "      Successfully uninstalled tensorflow-1.4.0\n",
      "Successfully installed protobuf-3.6.1 tensorboard-1.12.2 tensorflow-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import os\n",
    "import cv2\n",
    "import scipy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "\n",
    "def swish(x):\n",
    "    return (K.sigmoid(x) * x)\n",
    "\n",
    "get_custom_objects().update({'swish': Activation(swish)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2499 [00:00<?, ?it/s]/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/misc/pilutil.py:480: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if issubdtype(ts, int):\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/misc/pilutil.py:483: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  elif issubdtype(type(size), float):\n",
      "100%|██████████| 2499/2499 [00:09<00:00, 265.33it/s]\n",
      "100%|██████████| 2497/2497 [00:06<00:00, 390.61it/s]\n",
      "100%|██████████| 2478/2478 [00:06<00:00, 362.85it/s]\n",
      "100%|██████████| 2483/2483 [00:09<00:00, 261.16it/s]\n",
      "100%|██████████| 624/624 [00:01<00:00, 367.09it/s]\n",
      "100%|██████████| 623/623 [00:03<00:00, 189.22it/s]\n",
      "100%|██████████| 620/620 [00:03<00:00, 269.66it/s]\n",
      "100%|██████████| 620/620 [00:01<00:00, 412.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# What data should we load?\n",
    "# What to do with unlabeled data?\n",
    "def get_data(folder):\n",
    "    X, y, z = [], [], []\n",
    "    wbc_types = {'NEUTROPHIL': (0,1), 'EOSINOPHIL': (1,1), 'MONOCYTE': (2,0), 'LYMPHOCYTE': (3,0)}\n",
    "    for (wbc_type, labels) in wbc_types.items():  \n",
    "        for image_filename in tqdm(os.listdir(folder + wbc_type)):\n",
    "            img_file = cv2.imread(folder + wbc_type + '/' + image_filename)\n",
    "            if img_file is not None:\n",
    "                    img_file = scipy.misc.imresize(arr=img_file, size=(60, 80, 3))\n",
    "                    img_arr = np.asarray(img_file)\n",
    "                    X.append(img_arr)\n",
    "                    y.append(labels[0])\n",
    "                    z.append(labels[1])\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    z = np.asarray(z)\n",
    "    return X,y,z\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "X_train, y_train, z_train = get_data(\"blood-cells/dataset2-master/images/TRAIN/\")\n",
    "X_test, y_test, z_test = get_data(\"blood-cells/dataset2-master/images/TEST/\")\n",
    "y_trainHot = to_categorical(y_train, num_classes = 4)\n",
    "y_testHot = to_categorical(y_test, num_classes = 4)\n",
    "z_trainHot = to_categorical(z_train, num_classes = 2)\n",
    "z_testHot = to_categorical(z_test, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualization etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 60, 80, 3)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 60, 80, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 30, 40, 4)         304       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 20, 4)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 10, 4)          404       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 5, 4)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1296      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 2,084\n",
      "Trainable params: 2,078\n",
      "Non-trainable params: 6\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(*args, **kwargs):\n",
    "    inp = Input(shape=(60,80,3))\n",
    "    x = BatchNormalization()(inp)\n",
    "    x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='swish')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), padding=\"same\", strides=(2,2))(x)\n",
    "    x = Conv2D(4, 5, strides=(2, 2), padding='same', activation='swish')(x)\n",
    "    x = MaxPool2D(pool_size=(2, 2), padding=\"same\", strides=(2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(16, activation='swish')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    y = Dense(4, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inp, y)\n",
    "    opt = optimizers.Adam(lr=0.01, decay=0.0001)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=\"adam\",\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9957 samples, validate on 2487 samples\n",
      "Epoch 1/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 1.3492 - acc: 0.3223 - val_loss: 1.2117 - val_acc: 0.4033\n",
      "Epoch 2/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 1.1631 - acc: 0.4446 - val_loss: 1.0248 - val_acc: 0.5275\n",
      "Epoch 3/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.9952 - acc: 0.5549 - val_loss: 0.7281 - val_acc: 0.6940\n",
      "Epoch 4/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.7813 - acc: 0.6575 - val_loss: 0.6868 - val_acc: 0.7153\n",
      "Epoch 5/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.7158 - acc: 0.6796 - val_loss: 0.6394 - val_acc: 0.7205\n",
      "Epoch 6/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.6771 - acc: 0.6971 - val_loss: 0.6632 - val_acc: 0.7181\n",
      "Epoch 7/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.6447 - acc: 0.7129 - val_loss: 0.6272 - val_acc: 0.7314\n",
      "Epoch 8/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.6134 - acc: 0.7261 - val_loss: 0.6722 - val_acc: 0.7214\n",
      "Epoch 9/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.5903 - acc: 0.7389 - val_loss: 0.6492 - val_acc: 0.7402\n",
      "Epoch 10/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.5677 - acc: 0.7497 - val_loss: 0.6392 - val_acc: 0.7330\n",
      "Epoch 11/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.5485 - acc: 0.7573 - val_loss: 0.6441 - val_acc: 0.7459\n",
      "Epoch 12/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.5278 - acc: 0.7649 - val_loss: 0.6814 - val_acc: 0.7322\n",
      "Epoch 13/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.5195 - acc: 0.7677 - val_loss: 0.6131 - val_acc: 0.7479\n",
      "Epoch 14/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.4990 - acc: 0.7779 - val_loss: 0.6307 - val_acc: 0.7326\n",
      "Epoch 15/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.4945 - acc: 0.7812 - val_loss: 0.5689 - val_acc: 0.7551\n",
      "Epoch 16/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.4852 - acc: 0.7869 - val_loss: 0.7147 - val_acc: 0.7310\n",
      "Epoch 17/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.4674 - acc: 0.7933 - val_loss: 0.6714 - val_acc: 0.7479\n",
      "Epoch 18/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.4675 - acc: 0.7957 - val_loss: 0.5775 - val_acc: 0.7563\n",
      "Epoch 19/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.4535 - acc: 0.7965 - val_loss: 0.5805 - val_acc: 0.7612\n",
      "Epoch 20/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.4429 - acc: 0.8026 - val_loss: 0.6532 - val_acc: 0.7600\n",
      "Epoch 21/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.4359 - acc: 0.8043 - val_loss: 0.6962 - val_acc: 0.7374\n",
      "Epoch 22/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.4302 - acc: 0.8074 - val_loss: 0.5937 - val_acc: 0.7250\n",
      "Epoch 23/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.4245 - acc: 0.8092 - val_loss: 0.6131 - val_acc: 0.7495\n",
      "Epoch 24/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.4264 - acc: 0.8130 - val_loss: 0.5265 - val_acc: 0.7732\n",
      "Epoch 25/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.4188 - acc: 0.8124 - val_loss: 0.5536 - val_acc: 0.7543\n",
      "Epoch 26/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.4093 - acc: 0.8219 - val_loss: 0.6355 - val_acc: 0.7318\n",
      "Epoch 27/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.4060 - acc: 0.8204 - val_loss: 0.5588 - val_acc: 0.7752\n",
      "Epoch 28/80\n",
      "9957/9957 [==============================] - 17s 2ms/step - loss: 0.3996 - acc: 0.8195 - val_loss: 0.5140 - val_acc: 0.7620\n",
      "Epoch 29/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.4061 - acc: 0.8208 - val_loss: 0.6560 - val_acc: 0.7555\n",
      "Epoch 30/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.3834 - acc: 0.8312 - val_loss: 0.5781 - val_acc: 0.7579\n",
      "Epoch 31/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.3825 - acc: 0.8308 - val_loss: 0.5231 - val_acc: 0.7829\n",
      "Epoch 32/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.3831 - acc: 0.8298 - val_loss: 0.5562 - val_acc: 0.7793\n",
      "Epoch 33/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3847 - acc: 0.8313 - val_loss: 0.5657 - val_acc: 0.7740\n",
      "Epoch 34/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3717 - acc: 0.8328 - val_loss: 0.5705 - val_acc: 0.7616\n",
      "Epoch 35/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3723 - acc: 0.8354 - val_loss: 0.4951 - val_acc: 0.7793\n",
      "Epoch 36/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3670 - acc: 0.8411 - val_loss: 0.4893 - val_acc: 0.7889\n",
      "Epoch 37/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3579 - acc: 0.8432 - val_loss: 0.4494 - val_acc: 0.8002\n",
      "Epoch 38/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3555 - acc: 0.8439 - val_loss: 0.5365 - val_acc: 0.7861\n",
      "Epoch 39/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3664 - acc: 0.8381 - val_loss: 0.5329 - val_acc: 0.7853\n",
      "Epoch 40/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3562 - acc: 0.8437 - val_loss: 0.5202 - val_acc: 0.7893\n",
      "Epoch 41/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3625 - acc: 0.8422 - val_loss: 0.4867 - val_acc: 0.7901\n",
      "Epoch 42/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3458 - acc: 0.8455 - val_loss: 0.4831 - val_acc: 0.7998\n",
      "Epoch 43/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3468 - acc: 0.8452 - val_loss: 0.5001 - val_acc: 0.7873\n",
      "Epoch 44/80\n",
      "9957/9957 [==============================] - 23s 2ms/step - loss: 0.3537 - acc: 0.8429 - val_loss: 0.4290 - val_acc: 0.8150\n",
      "Epoch 45/80\n",
      "9957/9957 [==============================] - 22s 2ms/step - loss: 0.3446 - acc: 0.8509 - val_loss: 0.6078 - val_acc: 0.7692\n",
      "Epoch 46/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.3414 - acc: 0.8521 - val_loss: 0.5021 - val_acc: 0.8038\n",
      "Epoch 47/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.3424 - acc: 0.8536 - val_loss: 0.5315 - val_acc: 0.8050\n",
      "Epoch 48/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.3359 - acc: 0.8530 - val_loss: 0.6073 - val_acc: 0.7905\n",
      "Epoch 49/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3265 - acc: 0.8532 - val_loss: 0.4950 - val_acc: 0.7990\n",
      "Epoch 50/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.3333 - acc: 0.8522 - val_loss: 0.5744 - val_acc: 0.7809\n",
      "Epoch 51/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.3263 - acc: 0.8599 - val_loss: 0.5170 - val_acc: 0.8034\n",
      "Epoch 52/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.3265 - acc: 0.8566 - val_loss: 0.5117 - val_acc: 0.7748\n",
      "Epoch 53/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.3255 - acc: 0.8585 - val_loss: 0.5351 - val_acc: 0.7901\n",
      "Epoch 54/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.3226 - acc: 0.8559 - val_loss: 0.5637 - val_acc: 0.8042\n",
      "Epoch 55/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3254 - acc: 0.8543 - val_loss: 0.5140 - val_acc: 0.7965\n",
      "Epoch 56/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3274 - acc: 0.8565 - val_loss: 0.4288 - val_acc: 0.8166\n",
      "Epoch 57/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3173 - acc: 0.8601 - val_loss: 0.5220 - val_acc: 0.7921\n",
      "Epoch 58/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3271 - acc: 0.8521 - val_loss: 0.4808 - val_acc: 0.8030\n",
      "Epoch 59/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3237 - acc: 0.8537 - val_loss: 0.4372 - val_acc: 0.8166\n",
      "Epoch 60/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3254 - acc: 0.8553 - val_loss: 0.4967 - val_acc: 0.8006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3115 - acc: 0.8614 - val_loss: 0.5598 - val_acc: 0.7961\n",
      "Epoch 62/80\n",
      "9957/9957 [==============================] - 21s 2ms/step - loss: 0.3104 - acc: 0.8633 - val_loss: 0.4681 - val_acc: 0.8098\n",
      "Epoch 63/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3079 - acc: 0.8624 - val_loss: 0.5212 - val_acc: 0.7965\n",
      "Epoch 64/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3192 - acc: 0.8579 - val_loss: 0.5026 - val_acc: 0.7925\n",
      "Epoch 65/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3052 - acc: 0.8647 - val_loss: 0.4629 - val_acc: 0.8094\n",
      "Epoch 66/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.3101 - acc: 0.8640 - val_loss: 0.4625 - val_acc: 0.8162\n",
      "Epoch 67/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3155 - acc: 0.8610 - val_loss: 0.4559 - val_acc: 0.8243\n",
      "Epoch 68/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.2980 - acc: 0.8693 - val_loss: 0.4559 - val_acc: 0.8255\n",
      "Epoch 69/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.3010 - acc: 0.8630 - val_loss: 0.4637 - val_acc: 0.8090\n",
      "Epoch 70/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3110 - acc: 0.8625 - val_loss: 0.5255 - val_acc: 0.8066\n",
      "Epoch 71/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.2957 - acc: 0.8691 - val_loss: 0.4553 - val_acc: 0.8158\n",
      "Epoch 72/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.2968 - acc: 0.8682 - val_loss: 0.5534 - val_acc: 0.8014\n",
      "Epoch 73/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.3094 - acc: 0.8683 - val_loss: 0.5079 - val_acc: 0.8054\n",
      "Epoch 74/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.2967 - acc: 0.8728 - val_loss: 0.4992 - val_acc: 0.8034\n",
      "Epoch 75/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.3010 - acc: 0.8687 - val_loss: 0.4891 - val_acc: 0.8279\n",
      "Epoch 76/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.2960 - acc: 0.8704 - val_loss: 0.4788 - val_acc: 0.8070\n",
      "Epoch 77/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.2979 - acc: 0.8694 - val_loss: 0.5608 - val_acc: 0.8002\n",
      "Epoch 78/80\n",
      "9957/9957 [==============================] - 19s 2ms/step - loss: 0.2971 - acc: 0.8666 - val_loss: 0.5865 - val_acc: 0.7949\n",
      "Epoch 79/80\n",
      "9957/9957 [==============================] - 20s 2ms/step - loss: 0.2878 - acc: 0.8726 - val_loss: 0.5272 - val_acc: 0.8082\n",
      "Epoch 80/80\n",
      "9957/9957 [==============================] - 18s 2ms/step - loss: 0.2971 - acc: 0.8666 - val_loss: 0.4631 - val_acc: 0.8122\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "h = model.fit(X_train, y_trainHot, epochs=80, batch_size=32, validation_data=(X_test, y_testHot), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2487/2487 [==============================] - 2s 657us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.459717612023041, 0.5199034975674625]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test model\n",
    "model.evaluate(X_test, y_testHot, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
